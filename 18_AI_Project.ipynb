{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "18_AI_Project.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parkminjin99/18_AI_project/blob/main/18_AI_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMOmT6o2LI8u"
      },
      "source": [
        "### 필요한 라이브러리 설치"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVM0UZ_0LL14"
      },
      "source": [
        "!pip install pefile\n",
        "!pip install numpy\n",
        "!pip install sklearn\n",
        "!pip install lightgbm\n",
        "!pip install tqdm\n",
        "!pip install pandas\n",
        "!pip install graphviz\n",
        "!pip install overload\n",
        "!pip install lief"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orRRzVaCLVC0"
      },
      "source": [
        "### 구글 드라이브 연동 및 데이터 다운로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOn0diWJA0ny",
        "outputId": "592b3cde-eeb3-404a-a856-5396ff018f7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keIII2QCBq74"
      },
      "source": [
        "!unzip /content/drive/My\\ Drive/데이터.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdCXZkBhLYs8"
      },
      "source": [
        "### 사용할 헤더"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZgc6h0EBrCB"
      },
      "source": [
        "## Tutorial\n",
        "import os\n",
        "import glob\n",
        "import json\n",
        "import pprint\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_selection import RFE\n",
        "\n",
        "## PE-Miner\n",
        "import  pickle\n",
        "# import  peminer\n",
        "import  seaborn as  sns\n",
        "from  overload import  overload\n",
        "\n",
        "## Ember\n",
        "# import  ember\n",
        "import  pandas as  pd\n",
        "from  pprint import  pprint\n",
        "from  tqdm.notebook import  tqdm\n",
        "from  sklearn import  tree\n",
        "from  sklearn.metrics import  precision_score\n",
        "from  sklearn.metrics import  recall_score\n",
        "from  sklearn.metrics import  f1_score\n",
        "from  sklearn.metrics import  plot_confusion_matrix\n",
        "from  sklearn.metrics import  confusion_matrix\n",
        "from  sklearn.model_selection import  GridSearchCV\n",
        "import  matplotlib.pyplot as  plt\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SmvNpNbLbCS"
      },
      "source": [
        "### 파일 읽기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kyjjezGBrGv"
      },
      "source": [
        "def read_label_csv(path):\n",
        "    label_table = dict()\n",
        "    with open(path, \"r\", encoding = \"cp949\") as f: #csv파일을 읽는다\n",
        "        for line in f.readlines()[1:]:\n",
        "            fname, label = line.strip().split(\",\")\n",
        "            label_table[fname] = int(label)\n",
        "    return label_table\n",
        "\n",
        "def read_json(path):\n",
        "    with open(path, \"r\") as f:  #json파일을 읽는다 \n",
        "        return json.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5qFXrt5BrIr"
      },
      "source": [
        "learn_label_table = read_label_csv(\"학습데이터_정답.csv\")\n",
        "verify_label_table = read_label_csv(\"검증데이터_정답.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fR3Sl5BF0WF"
      },
      "source": [
        "###특징 벡터 생성 예시\n",
        "\n",
        "*   PEMINER 정보는 모두 수치형 데이터이므로 특별히 가공을 하지 않고 사용 가능\n",
        "*   EMBER, PESTUDIO 정보는 가공해서 사용해야 할 특징들이 있음 (e.g. imports, exports 등의 문자열 정보를 가지는 데이터)\n",
        "*   수치형 데이터가 아닌 데이터(범주형 데이터)를 어떻게 가공할 지가 관건 >> 인코딩 (e.g. 원핫인코딩, 레이블인코딩 등)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IA-2oSccBrNF"
      },
      "source": [
        "ember_path = \"EMBER/학습데이터/000c4ae5e00a1d4de991a9decf9ecbac59ed5582f5972f05b48bc1a1fe57338a.json\"\n",
        "peminer_path = \"PEMINER/학습데이터/000c4ae5e00a1d4de991a9decf9ecbac59ed5582f5972f05b48bc1a1fe57338a.json\"\n",
        "pestudio_path = \"PESTUDIO/학습데이터/bda2ab110f80f6fa79b3d650b6ae4565d8e840d7ba5b69e38c2874f63cc423a8.json\"\n",
        "\n",
        "ember_result = read_json(ember_path)\n",
        "peminer_result = read_json(peminer_path)\n",
        "pestudio_result = read_json(pestudio_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egeH7Fc1BrPd"
      },
      "source": [
        "pprint.pprint(ember_result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFTuW6iCBrSD"
      },
      "source": [
        "pprint.pprint(peminer_result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBLSzjf_BrU3"
      },
      "source": [
        "pprint.pprint(pestudio_result,depth = 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsCIDYxy73dU"
      },
      "source": [
        "> #### PE-Miner\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJRZiddIGPP9"
      },
      "source": [
        "class PeminerParser:\n",
        "    def __init__(self, path):\n",
        "        self.report = read_json(path)\n",
        "        self.vector = []\n",
        "    \n",
        "    def process_report(self):\n",
        "        '''\n",
        "            전체 데이터 사용        \n",
        "        '''\n",
        "        self.vector = [value for _, value in sorted(self.report.items(), key=lambda x: x[0])]\n",
        "        return self.vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNysM8xY75zR"
      },
      "source": [
        "\n",
        "\n",
        "> #### Ember\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjYVFWhTGP4o"
      },
      "source": [
        "class EmberParser:\n",
        "    '''\n",
        "        예제에서 사용하지 않은 특징도 사용하여 벡터화 할 것을 권장\n",
        "    '''\n",
        "    def __init__(self, path):\n",
        "        self.report = read_json(path)\n",
        "        self.vector = []\n",
        "    \n",
        "    def get_histogram_info(self):\n",
        "        histogram = np.array(self.report[\"histogram\"])\n",
        "        total = histogram.sum()\n",
        "        vector = histogram / total\n",
        "        return vector.tolist()\n",
        "    \n",
        "    def get_string_info(self):\n",
        "        strings = self.report[\"strings\"]\n",
        "\n",
        "        hist_divisor = float(strings['printables']) if strings['printables'] > 0 else 1.0\n",
        "        vector = [\n",
        "            strings['numstrings'], \n",
        "            strings['avlength'], \n",
        "            strings['printables'],\n",
        "            strings['entropy'], \n",
        "            strings['paths'], \n",
        "            strings['urls'],\n",
        "            strings['registry'], \n",
        "            strings['MZ']\n",
        "        ]\n",
        "        vector += (np.asarray(strings['printabledist']) / hist_divisor).tolist()\n",
        "        return vector\n",
        "    \n",
        "    def get_general_file_info(self):\n",
        "        general = self.report[\"general\"]\n",
        "        vector = [\n",
        "            general['size'], general['vsize'], general['has_debug'], general['exports'], general['imports'],\n",
        "            general['has_relocations'], general['has_resources'], general['has_signature'], general['has_tls'],\n",
        "            general['symbols']\n",
        "        ]\n",
        "        return vector\n",
        "\n",
        "    def process_report(self):\n",
        "        vector = []\n",
        "        vector += self.get_general_file_info()\n",
        "        vector += self.get_histogram_info()\n",
        "        vector += self.get_string_info()\n",
        "        '''\n",
        "            특징 추가\n",
        "        '''\n",
        "        return vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ffs9rJhA77RV"
      },
      "source": [
        "\n",
        "\n",
        "> #### PEstudio\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2RoaWWnGPt0"
      },
      "source": [
        "class PestudioParser:\n",
        "    '''\n",
        "        사용할 특징을 선택하여 벡터화 할 것을 권장\n",
        "    '''\n",
        "    \n",
        "    def __init__(self, path):\n",
        "        self.report = read_json(path)\n",
        "        self.vector = []\n",
        "    \n",
        "    def process_report(self):\n",
        "        pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wH_fYIR_GoO6"
      },
      "source": [
        "### 학습데이터 구성\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPkRA4hf-wVE"
      },
      "source": [
        "> #### PE-Miner"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lx-P4FMQQ3e8"
      },
      "source": [
        "import os\n",
        "import queue\n",
        "\n",
        "peminer_data = []\n",
        "\n",
        "def get_subdir(path):\n",
        "    global peminer_data\n",
        "    try:  # 검색이 허가되지 않은 디렉토리 접근에 관한 예외처리\n",
        "        dirfiles = os.listdir(path)  # path에 해당하는 디렉토리 dirfiles에 추가\n",
        "    except PermissionError:\n",
        "        return []\n",
        "\n",
        "    subdir_list = []\n",
        "    for each in dirfiles:\n",
        "        if each.endswith(\".json\"):  # .txt로 끝나는 파일은 따로 all_txt리스트에 저장\n",
        "            peminer_data.append(path + each)\n",
        "        full_name = path + each  # path와 each(디렉토리)\n",
        "        if os.path.isdir(full_name):\n",
        "            subdir_list.append(full_name + \"/\")\n",
        "    return subdir_list\n",
        "\n",
        "\n",
        "dir_queue = queue.Queue()\n",
        "# /Library/ 아래의 모든 하위 디렉토리 찾기\n",
        "dir_queue.put(\"PEMINER/학습데이터/\")  # 검색하고자 하는 디렉토리를 줄 앞에 세움\n",
        "\n",
        "while not dir_queue.empty():  # 큐가 비어있는 상태인지 확인\n",
        "    dir_name = dir_queue.get()  # 큐에서 빼낸 dir_name\n",
        "    subdir_names = get_subdir(dir_name)  # dir_name의 하위 디렉토리를 subdir_names에 저장\n",
        "    for each in subdir_names:  # subdir_names리스트에 있는 디렉토리들을 다시 큐에 넣음\n",
        "        dir_queue.put(each)\n",
        "\n",
        "for dir in peminer_data:\n",
        "    print(dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezMKvx18-yiy"
      },
      "source": [
        "> #### Ember"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJ-RQSBTXqGg"
      },
      "source": [
        "import os\n",
        "import queue\n",
        "\n",
        "ember_data = []\n",
        "\n",
        "def get_subdir(path):\n",
        "    global ember_data\n",
        "    try:  # 검색이 허가되지 않은 디렉토리 접근에 관한 예외처리\n",
        "        dirfiles = os.listdir(path)  # path에 해당하는 디렉토리 dirfiles에 추가\n",
        "    except PermissionError:\n",
        "        return []\n",
        "\n",
        "    subdir_list = []\n",
        "    for each in dirfiles:\n",
        "        if each.endswith(\".json\"):  # .txt로 끝나는 파일은 따로 all_txt리스트에 저장\n",
        "            ember_data.append(path + each)\n",
        "        full_name = path + each  # path와 each(디렉토리)\n",
        "        if os.path.isdir(full_name):\n",
        "            subdir_list.append(full_name + \"/\")\n",
        "    return subdir_list\n",
        "\n",
        "\n",
        "dir_queue = queue.Queue()\n",
        "# /Library/ 아래의 모든 하위 디렉토리 찾기\n",
        "dir_queue.put(\"EMBER/학습데이터/\")  # 검색하고자 하는 디렉토리를 줄 앞에 세움\n",
        "\n",
        "while not dir_queue.empty():  # 큐가 비어있는 상태인지 확인\n",
        "    dir_name = dir_queue.get()  # 큐에서 빼낸 dir_name\n",
        "    subdir_names = get_subdir(dir_name)  # dir_name의 하위 디렉토리를 subdir_names에 저장\n",
        "    for each in subdir_names:  # subdir_names리스트에 있는 디렉토리들을 다시 큐에 넣음\n",
        "        dir_queue.put(each)\n",
        "\n",
        "for dir in ember_data:\n",
        "    print(dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xg8CbdCV-1QV"
      },
      "source": [
        "> #### PE-Miner + Ember"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_wfhNejGnrd",
        "outputId": "7ef67e48-fce9-4396-be92-e74f2ed28706",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 데이터의 특징 벡터 모음(2차원 리스트) : X\n",
        "# 데이터의 레이블 모음(1차원 리스트) : y\n",
        "X, y = [], []\n",
        "\n",
        "for path in peminer_data:\n",
        "  feature_vector = []\n",
        "  temp, fdata, fname = path.strip().split(\"/\")\n",
        "  fname = fname.replace(\".json\",\"\")\n",
        "  label = learn_label_table[fname]\n",
        "  for data in [\"PEMINER\", \"EMBER\"]:\n",
        "        path = f\"{data}/{fdata}/{fname}.json\"\n",
        "        if data == \"PEMINER\":\n",
        "            feature_vector += PeminerParser(path).process_report()\n",
        "        else:\n",
        "            feature_vector += EmberParser(path).process_report()\n",
        "  X.append(feature_vector)\n",
        "  y.append(label)\n",
        "\n",
        "for path in ember_data:\n",
        "  feature_vector = []\n",
        "  temp, fdata, fname = path.strip().split(\"/\")\n",
        "  fname = fname.replace(\".json\",\"\")\n",
        "  label = learn_label_table[fname]\n",
        "  for data in [\"PEMINER\", \"EMBER\"]:\n",
        "        path = f\"{data}/{fdata}/{fname}.json\"\n",
        "        if data == \"PEMINER\":\n",
        "            feature_vector += PeminerParser(path).process_report()\n",
        "        else:\n",
        "            feature_vector += EmberParser(path).process_report()\n",
        "  X.append(feature_vector)\n",
        "  y.append(label)\n",
        "\n",
        "np.asarray(X).shape, np.asarray(y).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((40000, 558), (40000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiVxs_7cbuFD",
        "outputId": "e8fd910e-ae41-4905-d00d-f901a4b4a215",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X, y = [], []\n",
        "for fname_ in [\"학습데이터/000c4ae5e00a1d4de991a9decf9ecbac59ed5582f5972f05b48bc1a1fe57338a\", \"학습데이터/00ed7bc707559e6e63818b2bba0ac6b338ba17d95aea6f0838cbdc40cb9acd94\"]:\n",
        "    feature_vector = []\n",
        "    fdata, fname = fname_.strip().split(\"/\")\n",
        "    label = learn_label_table[fname]\n",
        "    for data in [\"PEMINER\", \"EMBER\"]:\n",
        "        path = f\"{data}/{fname_}.json\"\n",
        "        if data == \"PEMINER\":\n",
        "            feature_vector += PeminerParser(path).process_report()\n",
        "        else:\n",
        "            feature_vector += EmberParser(path).process_report()\n",
        "    X.append(feature_vector)\n",
        "    y.append(label)\n",
        "\n",
        "np.asarray(X).shape, np.asarray(y).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2, 558), (2,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJoqBTsAIaPG"
      },
      "source": [
        "### 검증데이터 구성"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4lwCHe4-8_i"
      },
      "source": [
        "> #### PE-Miner"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSdc5ApKGQ9z"
      },
      "source": [
        "import os\n",
        "import queue\n",
        "\n",
        "peminer_veri_data = []\n",
        "\n",
        "def get_subdir(path):\n",
        "    global peminer_veri_data\n",
        "    try:  # 검색이 허가되지 않은 디렉토리 접근에 관한 예외처리\n",
        "        dirfiles = os.listdir(path)  # path에 해당하는 디렉토리 dirfiles에 추가\n",
        "    except PermissionError:\n",
        "        return []\n",
        "\n",
        "    subdir_list = []\n",
        "    for each in dirfiles:\n",
        "        if each.endswith(\".json\"):  # .txt로 끝나는 파일은 따로 all_txt리스트에 저장\n",
        "            peminer_veri_data.append(path + each)\n",
        "        full_name = path + each  # path와 each(디렉토리)\n",
        "        if os.path.isdir(full_name):\n",
        "            subdir_list.append(full_name + \"/\")\n",
        "    return subdir_list\n",
        "\n",
        "\n",
        "dir_queue = queue.Queue()\n",
        "# /Library/ 아래의 모든 하위 디렉토리 찾기\n",
        "dir_queue.put(\"PEMINER/검증데이터/\")  # 검색하고자 하는 디렉토리를 줄 앞에 세움\n",
        "\n",
        "while not dir_queue.empty():  # 큐가 비어있는 상태인지 확인\n",
        "    dir_name = dir_queue.get()  # 큐에서 빼낸 dir_name\n",
        "    subdir_names = get_subdir(dir_name)  # dir_name의 하위 디렉토리를 subdir_names에 저장\n",
        "    for each in subdir_names:  # subdir_names리스트에 있는 디렉토리들을 다시 큐에 넣음\n",
        "        dir_queue.put(each)\n",
        "\n",
        "for dir in peminer_veri_data:\n",
        "    print(dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7VwjN4s--rj"
      },
      "source": [
        "> #### Ember"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4rO4P3YnB7X"
      },
      "source": [
        "import os\n",
        "import queue\n",
        "\n",
        "ember_veri_data = []\n",
        "\n",
        "def get_subdir(path):\n",
        "    global ember_veri_data\n",
        "    try:  # 검색이 허가되지 않은 디렉토리 접근에 관한 예외처리\n",
        "        dirfiles = os.listdir(path)  # path에 해당하는 디렉토리 dirfiles에 추가\n",
        "    except PermissionError:\n",
        "        return []\n",
        "\n",
        "    subdir_list = []\n",
        "    for each in dirfiles:\n",
        "        if each.endswith(\".json\"):  # .txt로 끝나는 파일은 따로 all_txt리스트에 저장\n",
        "            ember_veri_data.append(path + each)\n",
        "        full_name = path + each  # path와 each(디렉토리)\n",
        "        if os.path.isdir(full_name):\n",
        "            subdir_list.append(full_name + \"/\")\n",
        "    return subdir_list\n",
        "\n",
        "\n",
        "dir_queue = queue.Queue()\n",
        "# /Library/ 아래의 모든 하위 디렉토리 찾기\n",
        "dir_queue.put(\"EMBER/검증데이터/\")  # 검색하고자 하는 디렉토리를 줄 앞에 세움\n",
        "\n",
        "while not dir_queue.empty():  # 큐가 비어있는 상태인지 확인\n",
        "    dir_name = dir_queue.get()  # 큐에서 빼낸 dir_name\n",
        "    subdir_names = get_subdir(dir_name)  # dir_name의 하위 디렉토리를 subdir_names에 저장\n",
        "    for each in subdir_names:  # subdir_names리스트에 있는 디렉토리들을 다시 큐에 넣음\n",
        "        dir_queue.put(each)\n",
        "\n",
        "for dir in ember_veri_data:\n",
        "    print(dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ru0m5H42_BU7"
      },
      "source": [
        "> #### PE-Miner + Ember"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XskaeAIdnCNY",
        "outputId": "f90f533a-394b-4f5e-ce0f-b47e1335035e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 데이터의 특징 벡터 모음(2차원 리스트) : X\n",
        "# 데이터의 레이블 모음(1차원 리스트) : y\n",
        "A, b = [], []\n",
        "\n",
        "for path in peminer_veri_data:\n",
        "  feature_vector = []\n",
        "  temp, fdata, fname = path.strip().split(\"/\")\n",
        "  fname = fname.replace(\".json\",\"\")\n",
        "  label = verify_label_table[fname]\n",
        "  for data in [\"PEMINER\", \"EMBER\"]:\n",
        "        path = f\"{data}/{fdata}/{fname}.json\"\n",
        "        if data == \"PEMINER\":\n",
        "            feature_vector += PeminerParser(path).process_report()\n",
        "        else:\n",
        "            feature_vector += EmberParser(path).process_report()\n",
        "  A.append(feature_vector)\n",
        "  b.append(label)\n",
        "\n",
        "for path in ember_veri_data:\n",
        "  feature_vector = []\n",
        "  temp, fdata, fname = path.strip().split(\"/\")\n",
        "  fname = fname.replace(\".json\",\"\")\n",
        "  label = verify_label_table[fname]\n",
        "  for data in [\"PEMINER\", \"EMBER\"]:\n",
        "        path = f\"{data}/{fdata}/{fname}.json\"\n",
        "        if data == \"PEMINER\":\n",
        "            feature_vector += PeminerParser(path).process_report()\n",
        "        else:\n",
        "            feature_vector += EmberParser(path).process_report()\n",
        "  A.append(feature_vector)\n",
        "  b.append(label)\n",
        "\n",
        "np.asarray(A).shape, np.asarray(b).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((20000, 558), (20000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7D4p7EzGHzbm"
      },
      "source": [
        "### 학습 및 검증"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjDcWbxPH5Nn"
      },
      "source": [
        "SEED = 41\n",
        "\n",
        "def load_model(**kwargs):\n",
        "    if kwargs[\"model\"] == \"rf\":\n",
        "        return RandomForestClassifier(random_state=kwargs[\"random_state\"], n_jobs=4)\n",
        "    elif kwargs[\"model\"] == \"dt\": # decision tree\n",
        "        return DecisionTreeClassifier(random_state=kwargs[\"random_state\"])\n",
        "    elif kwargs[\"model\"] == \"lgb\":\n",
        "        return LGBMClassifier(random_state=kwargs[\"random_state\"])\n",
        "    elif kwargs[\"model\"] == \"svm\":\n",
        "        return SVC(random_state=kwargs[\"random_state\"])\n",
        "    elif kwargs[\"model\"] == \"lr\":\n",
        "        return LogisticRegression(random_state=kwargs[\"random_state\"], n_jobs=-1)\n",
        "    elif kwargs[\"model\"] == \"knn\":\n",
        "        return KNeighborsClassifier(n_jobs=-1)\n",
        "    elif kwargs[\"model\"] == \"adaboost\":\n",
        "        return AdaBoostClassifier(random_state=kwargs[\"random_state\"])\n",
        "    elif kwargs[\"model\"] == \"mlp\":\n",
        "        return MLPClassifier(random_state=kwargs[\"random_state\"])\n",
        "    else:\n",
        "        print(\"Unsupported Algorithm\")\n",
        "        return None\n",
        "\n",
        "def train(X_train, y_train, model):\n",
        "    '''\n",
        "        머신러닝 모델을 선택하여 학습을 진행하는 함수\n",
        "\t\n",
        "        :param X_train: 학습할 2차원 리스트 특징벡터\n",
        "        :param y_train: 학습할 1차원 리스트 레이블 벡터\n",
        "        :param model: 문자열, 선택할 머신러닝 알고리즘\n",
        "        :return: 학습된 머신러닝 모델 객체\n",
        "    '''\n",
        "    clf = load_model(model=model, random_state=SEED)\n",
        "    clf.fit(X_train, y_train)\n",
        "    return clf\n",
        "\n",
        "def evaluate(X_test, y_test, model):\n",
        "    '''\n",
        "        학습된 머신러닝 모델로 검증 데이터를 검증하는 함수\n",
        "\t\n",
        "        :param X_test: 검증할 2차원 리스트 특징 벡터\n",
        "        :param y_test: 검증할 1차원 리스트 레이블 벡터\n",
        "        :param model: 학습된 머신러닝 모델 객체\n",
        "    '''\n",
        "    predict = model.predict(X_test)\n",
        "    print(\"정확도\", model.score(X_test, y_test))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbWTdCAdGRAr",
        "outputId": "02f0c47f-c671-44fd-816d-2a4e897897d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 학습\n",
        "models = []\n",
        "for model in [\"rf\", \"lgb\"]:\n",
        "    clf = train(X, y, model)\n",
        "    models.append(clf)\n",
        "\n",
        "# 검증\n",
        "# 실제 검증 시에는 제공한 검증데이터를 검증에 사용해야 함\n",
        "for model in models:\n",
        "    evaluate(A, b, model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "정확도 0.9436\n",
            "정확도 0.9523\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BymEmm0qN8C"
      },
      "source": [
        "### 앙상블 예제"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpMv5cR0GRGt"
      },
      "source": [
        "def ensemble_result(X, y, models):\n",
        "    '''\n",
        "        학습된 모델들의 결과를 앙상블하는 함수\n",
        "\t\n",
        "        :param X: 검증할 2차원 리스트 특징 벡터\n",
        "        :param y: 검증할 1차원 리스트 레이블 벡터\n",
        "        :param models: 1개 이상의 학습된 머신러닝 모델 객체를 가지는 1차원 리스트\n",
        "    '''\n",
        "    \n",
        "    # Soft Voting\n",
        "    # https://devkor.tistory.com/entry/Soft-Voting-%EA%B3%BC-Hard-Voting\n",
        "    predicts = []\n",
        "    for i in range(len(X)):\n",
        "        probs = []\n",
        "        for model in models:\n",
        "            prob = model.predict_proba(X)[i][1]\n",
        "            probs.append(prob)\n",
        "        predict = 1 if np.mean(probs) >= 0.5 else 0\n",
        "        predicts.append(predict)\n",
        "        \n",
        "    print(\"정확도\", accuracy_score(y, predicts))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cYbnqlhGRLj"
      },
      "source": [
        "ensemble_result(A, b, models)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ta0byRCtCJRp"
      },
      "source": [
        "### 특징 선택 예제 (RFE 알고리즘 사용)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_wO8elFGRSE"
      },
      "source": [
        "def select_feature(X, y, model):\n",
        "    '''\n",
        "        주어진 특징 벡터에서 특정 알고리즘 기반 특징 선택\n",
        "        \n",
        "        본 예제에서는 RFE 알고리즘 사용\n",
        "        https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html#sklearn.feature_selection.RFE.fit_transform\n",
        "        \n",
        "        :param X: 검증할 2차원 리스트 특징 벡터\n",
        "        :param y: 검증할 1차원 리스트 레이블 벡터\n",
        "        :param model: 문자열, 특징 선택에 사용할 머신러닝 알고리즘\n",
        "    '''\n",
        "    \n",
        "    model = load_model(model=model, random_state=SEED)\n",
        "    rfe = RFE(estimator=model)\n",
        "    return rfe.fit_transform(X, y)\n",
        "\n",
        "selected_X = select_feature(X, y, \"rf\")\n",
        "new_model = train(selected_X, y, \"rf\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBOCaPdmCNws"
      },
      "source": [
        "### 피처 추출"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1KDkSChCSnV"
      },
      "source": [
        "> #### PE-Miner로"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxubqDvDGRUc"
      },
      "source": [
        "# PEMINER 에서 사용한 특징의 이름\n",
        "peminer_header = ['ADVAP132.DLL', 'AWFAXP32.DLL', 'AWFXAB32.DLL', 'AWPWD32.DLL', 'AWRESX32.DLL', 'AWUTIL32.DLL', 'BHNETB.DLL', 'BHSUPP.DLL', 'CCAPI.DLL', 'CCEI.DLL', 'CCPSH.DLL', 'CCTN20.DLL', 'CMC.DLL', 'COMCTL32.DLL', 'COMDLG32.DLL', 'CRTDLL.DLL', 'DCIMAN.DLL', 'DCIMAN32.DLL', 'DSKMAINT.DLL', 'FileHeader.Characteristics', 'FileHeader.Machine', 'FileHeader.NumberOfSections', 'FileHeader.NumberOfSymbols', 'FileHeader.PointerToSymbolTable', 'FileHeader.SizeOfOptionalHeader', 'FileHeader.TimeDateStamp', 'GDI32.DLL', 'GROUP.DLL', 'HYPERTERM.DLL', 'KERNL32.DLL', 'LZ32.DLL', 'MAPI.DLL', 'MAPI32.DLL', 'MFC30.DLL', 'MPR.DLL', 'MSFS32.DLL', 'MSNDUI.DLL', 'MSNET32.DLL', 'MSPST32.DLL', 'MSSHRUI.DLL', 'MSVIEWUT.DLL', 'NAL.DLL', 'NDIS30.DLL', 'NETAPI.DLL', 'NETAPI32.DLL', 'NETBIOS.DLL', 'NETDI.DLL', 'NETSETUP.DLL', 'NWAB32.DLL', 'NWNET32.DLL', 'NWNP32.DLL', 'OLEDLG.DLL', 'OptionalHeader.AddressOfEntryPoint', 'OptionalHeader.BaseOfCode', 'OptionalHeader.BaseOfData', 'OptionalHeader.CheckSum', 'OptionalHeader.DataDirectory.IMAGE_DIRECTORY_ENTRY_BASERELOC.Size', 'OptionalHeader.DataDirectory.IMAGE_DIRECTORY_ENTRY_BASERELOC.VirtualAddress', 'OptionalHeader.DataDirectory.IMAGE_DIRECTORY_ENTRY_BOUND_IMPORT.Size', 'OptionalHeader.DataDirectory.IMAGE_DIRECTORY_ENTRY_BOUND_IMPORT.VirtualAddress', 'OptionalHeader.DataDirectory.IMAGE_DIRECTORY_ENTRY_COM_DESCRIPTOR.Size', 'OptionalHeader.DataDirectory.IMAGE_DIRECTORY_ENTRY_COM_DESCRIPTOR.VirtualAddress', 'OptionalHeader.DataDirectory.IMAGE_DIRECTORY_ENTRY_DEBUG.Size', 'OptionalHeader.DataDirectory.IMAGE_DIRECTORY_ENTRY_DEBUG.VirtualAddress', 'OptionalHeader.DataDirectory.IMAGE_DIRECTORY_ENTRY_DELAY_IMPORT.Size', 'OptionalHeader.DataDirectory.IMAGE_DIRECTORY_ENTRY_DELAY_IMPORT.VirtualAddress', 'OptionalHeader.DataDirectory.IMAGE_DIRECTORY_ENTRY_EXCEPTION.Size', 'OptionalHeader.DataDirectory.IMAGE_DIRECTORY_ENTRY_EXCEPTION.VirtualAddress', 'OptionalHeader.DataDirectory.IMAGE_DIRECTORY_ENTRY_EXPORT.Size', 'OptionalHeader.DataDirectory.IMAGE_DIRECTORY_ENTRY_EXPORT.VirtualAddress', 'OptionalHeader.DataDirectory.IMAGE_DIRECTORY_ENTRY_GLOBALPTR.Size', 'OptionalHeader.DataDirectory.IMAGE_DIRECTORY_ENTRY_GLOBALPTR.VirtualAddress', 'OptionalHeader.DataDirectory.IMAGE_DIRECTORY_ENTRY_IAT.Size', 'OptionalHeader.DataDirectory.IMAGE_DIRECTORY_ENTRY_IAT.VirtualAddress', 'OptionalHeader.DataDirectory.IMAGE_DIRECTORY_ENTRY_IMPORT.Size', 'OptionalHeader.DataDirectory.IMAGE_DIRECTORY_ENTRY_IMPORT.VirtualAddress', 'OptionalHeader.DataDirectory.IMAGE_DIRECTORY_ENTRY_LOAD_CONFIG.Size', 'OptionalHeader.DataDirectory.IMAGE_DIRECTORY_ENTRY_LOAD_CONFIG.VirtualAddress', 'OptionalHeader.DataDirectory.IMAGE_DIRECTORY_ENTRY_RESERVED.Size', 'OptionalHeader.DataDirectory.IMAGE_DIRECTORY_ENTRY_RESERVED.VirtualAddress', 'OptionalHeader.DataDirectory.IMAGE_DIRECTORY_ENTRY_RESOURCE.Size', 'OptionalHeader.DataDirectory.IMAGE_DIRECTORY_ENTRY_RESOURCE.VirtualAddress', 'OptionalHeader.DataDirectory.IMAGE_DIRECTORY_ENTRY_SECURITY.Size', 'OptionalHeader.DataDirectory.IMAGE_DIRECTORY_ENTRY_SECURITY.VirtualAddress', 'OptionalHeader.DataDirectory.IMAGE_DIRECTORY_ENTRY_TLS.Size', 'OptionalHeader.DataDirectory.IMAGE_DIRECTORY_ENTRY_TLS.VirtualAddress', 'OptionalHeader.DllCharacteristics', 'OptionalHeader.FileAlignment', 'OptionalHeader.ImageBase', 'OptionalHeader.LoaderFlags', 'OptionalHeader.Magic', 'OptionalHeader.MajorImageVersion', 'OptionalHeader.MajorLinkerVersion', 'OptionalHeader.MajorOperatingSystemVersion', 'OptionalHeader.MajorSubsystemVersion', 'OptionalHeader.MinorImageVersion', 'OptionalHeader.MinorLinkerVersion', 'OptionalHeader.MinorOperatingSystemVersion', 'OptionalHeader.MinorSubsystemVersion', 'OptionalHeader.NumberOfRvaAndSizes', 'OptionalHeader.Reserved1', 'OptionalHeader.SectionAlignment', 'OptionalHeader.SizeOfCode', 'OptionalHeader.SizeOfHeaders', 'OptionalHeader.SizeOfHeapCommit', 'OptionalHeader.SizeOfHeapReserve', 'OptionalHeader.SizeOfImage', 'OptionalHeader.SizeOfInitializedData', 'OptionalHeader.SizeOfStackCommit', 'OptionalHeader.SizeOfStackReserve', 'OptionalHeader.SizeOfUninitializedData', 'OptionalHeader.Subsystem', 'POWERCFG.DLL', 'RASAPI16.DLL', 'RASAPI32.DLL', 'RASPI.DLL', 'RPCLTC1.DLL', 'RPCNS4.DLL', 'RPCRT4.DLL', 'RPCTLC3.DLL', 'RPCTLC5.DLL', 'RPCTLC6.DLL', 'RPCTLS3.DLL', 'RPCTLS5.DLL', 'RPCTLS6.DLL', 'RSRC32.DLL', 'Resource.Characteristics', 'Resource.MajorVersion', 'Resource.MinorVersion', 'Resource.NumberOfIdEntries', 'Resource.NumberOfNamedEntries', 'Resource.RT_ACCELERATOR', 'Resource.RT_BITMAP', 'Resource.RT_CURSOR', 'Resource.RT_DIALOG', 'Resource.RT_DLGINCLUDE', 'Resource.RT_FONT', 'Resource.RT_FONTDIR', 'Resource.RT_GROUP_CURSOR', 'Resource.RT_GROUP_ICON', 'Resource.RT_ICON', 'Resource.RT_MENU', 'Resource.RT_MESSAGETABLE', 'Resource.RT_RCDATA', 'Resource.RT_STRING', 'Resource.RT_VERSION', 'Resource.TimeDateStamp', 'SAPNSP.DLL', 'SECUR32.DLL', 'SHELL32.DLL', 'SHLWAPI.DLL', 'SLENH.DLL', 'Section.data.Characteristics', 'Section.data.NumberOfLinenumbers', 'Section.data.NumberOfRelocations', 'Section.data.PointerToLinenumbers', 'Section.data.PointerToRawData', 'Section.data.PointerToRelocations', 'Section.data.SizeOfRawData', 'Section.data.VirtualAddress', 'Section.data.VirtualSize', 'Section.rsrc.Characteristics', 'Section.rsrc.NumberOfLinenumbers', 'Section.rsrc.NumberOfRelocations', 'Section.rsrc.PointerToLinenumbers', 'Section.rsrc.PointerToRawData', 'Section.rsrc.PointerToRelocations', 'Section.rsrc.SizeOfRawData', 'Section.rsrc.VirtualAddress', 'Section.rsrc.VirtualSize', 'Section.text.Characteristics', 'Section.text.NumberOfLinenumbers', 'Section.text.NumberOfRelocations', 'Section.text.PointerToLinenumbers', 'Section.text.PointerToRawData', 'Section.text.PointerToRelocations', 'Section.text.SizeOfRawData', 'Section.text.VirtualAddress', 'Section.text.VirtualSize', 'UMDM32.DLL', 'USER32.DLL', 'VERSION.DLL', 'WININET.DLL', 'WINMM.DLL', 'WINREG.DLL', 'WINSOCK.DLL', 'WS2.DLL', 'WSOCK32.DLL']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqKnwHOOGRXS"
      },
      "source": [
        "# 피클 파일 로드\n",
        "def read_pickle(path):\n",
        "    with open(path, \"rb\") as f:\n",
        "        return pickle.load(f)\n",
        "\n",
        "# 피클 파일 저장\n",
        "def save_pickle(path, data):\n",
        "    with open(path, \"wb\") as f:\n",
        "        pickle.dump(data, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-AwN4D-Cf4I"
      },
      "source": [
        "> #### Ember로"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BW4R6QPZClaC"
      },
      "source": [
        "def read_bytes(path):\n",
        "    with open(path, \"rb\") as f:\n",
        "        return f.read()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKVBoTLfC6Le"
      },
      "source": [
        "example_path = os.path.join(drive_path, \"My Drive\", \"sample.exe\")\n",
        "\n",
        "raw = read_bytes(example_path)\n",
        "generator = ember.PEFeatureExtractor()\n",
        "\n",
        "generator.raw_features(raw)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVf1LRcFC6N8"
      },
      "source": [
        "generator.feature_vector(raw)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAvZ8Pt0C6QS"
      },
      "source": [
        "def read_pickle(path):\n",
        "    with open(path, \"rb\") as f:\n",
        "        return pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smCIGoX-DxxL"
      },
      "source": [
        "### 데이터 로드"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNXmdfiWD2EU"
      },
      "source": [
        "> #### PE-Miner"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSbv5aw2EpSi"
      },
      "source": [
        "전체 데이터 특징 추출 및 저장 예제 코드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ch-2xYOC6Tc"
      },
      "source": [
        "data = []\n",
        "for path in paths:\n",
        "    # 각 파일의 피처 추출 후 피처 벡터 생성\n",
        "    vector = np.array([ value for _, value in sorted(peminer.extract_feature(path).items(), key=lambda x : x[0])])\n",
        "    data.append(vector)\n",
        "save_pickle(\"data_path.pkl\", data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bZkYZzYEL_J"
      },
      "source": [
        "fname_train = np.load(os.path.join(drive_path, \"My Drive\", \"new_peminer_train_fnames.npy\"))\n",
        "X_train = pd.DataFrame(np.load(os.path.join(drive_path, \"My Drive\", \"new_peminer_train_features.npy\")), columns=peminer_header)\n",
        "y_train = np.load(os.path.join(drive_path, \"My Drive\", \"new_peminer_train_labels.npy\"))\n",
        "\n",
        "fname_test = np.load(os.path.join(drive_path, \"My Drive\", \"new_peminer_test_fnames.npy\"))\n",
        "X_test = pd.DataFrame(np.load(os.path.join(drive_path, \"My Drive\", \"new_peminer_test_features.npy\")), columns=peminer_header)\n",
        "y_test = np.load(os.path.join(drive_path, \"My Drive\", \"new_peminer_test_labels.npy\"))\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8H57_gmD9dX"
      },
      "source": [
        "> #### Ember"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HcJ0s72EBGP"
      },
      "source": [
        "X_train = read_pickle(os.path.join(drive_path, \"My Drive\", \"ember_train_features.pkl\"))\n",
        "y_train = read_pickle(os.path.join(drive_path, \"My Drive\", \"ember_train_labels.pkl\"))\n",
        "\n",
        "X_test = read_pickle(os.path.join(drive_path, \"My Drive\", \"ember_test_features.pkl\"))\n",
        "y_test = read_pickle(os.path.join(drive_path, \"My Drive\", \"ember_test_labels.pkl\"))\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irhLpbKJFSQX"
      },
      "source": [
        "### 학습 및 테스트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjdOvPriF_Sh"
      },
      "source": [
        "# 고정 시드값\n",
        "SEED = 41\n",
        "\n",
        "# 학습 알고리즘 선택 함수\n",
        "def load_model(**kwargs):\n",
        "    if kwargs[\"model\"] == \"rf\":\n",
        "        return RandomForestClassifier(random_state=kwargs[\"random_state\"], n_jobs=4)\n",
        "    elif kwargs[\"model\"] == \"dt\":\n",
        "        return DecisionTreeClassifier(random_state=kwargs[\"random_state\"])\n",
        "    elif kwargs[\"model\"] == \"lgb\":\n",
        "        return LGBMClassifier(random_state=kwargs[\"random_state\"])\n",
        "    elif kwargs[\"model\"] == \"svm\":\n",
        "        return SVC(random_state=kwargs[\"random_state\"])\n",
        "    elif kwargs[\"model\"] == \"lr\":\n",
        "        return LogisticRegression(random_state=kwargs[\"random_state\"], n_jobs=-1)\n",
        "    elif kwargs[\"model\"] == \"knn\":\n",
        "        return KNeighborsClassifier(n_jobs=-1)\n",
        "    elif kwargs[\"model\"] == \"adaboost\":\n",
        "        return AdaBoostClassifier(random_state=kwargs[\"random_state\"])\n",
        "    elif kwargs[\"model\"] == \"mlp\":\n",
        "        return MLPClassifier(random_state=kwargs[\"random_state\"])\n",
        "    else:\n",
        "        print(\"Unsupported Algorithm\")\n",
        "        return None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQQHc3hQFX1s"
      },
      "source": [
        "\n",
        "\n",
        "> #### PE-Miner\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOEfJ19-FT1J"
      },
      "source": [
        "import hashlib\n",
        "import pprint\n",
        "\n",
        "def train(X_train, y_train, model=\"rf\"):\n",
        "    print(X_train.shape)\n",
        "\n",
        "    # 학습 알고리즘 불러오기\n",
        "    # 랜덤 포레스트 : rf\n",
        "    # 의사결정 트리 : dt\n",
        "    # lightgbm : lgb\n",
        "    # svm : svm\n",
        "    # logistic regression : lr\n",
        "    # knn : knn\n",
        "    # adaboost : adaboost\n",
        "    # mlp : mlp\n",
        "    clf = load_model(model=model, random_state=SEED)\n",
        "    # 학습\n",
        "    clf.fit(X_train, y_train)\n",
        "    return clf\n",
        "\n",
        "\n",
        "def evaluate(clf, X_test, y_test):\n",
        "    # 예측\n",
        "    predict = clf.predict(X_test)\n",
        "\n",
        "    # 성능 확인\n",
        "    print(\"accuracy\", clf.score(X_test, y_test))\n",
        "    print(\"precision\", precision_score(y_test, predict))\n",
        "    print(\"recall\", recall_score(y_test, predict))\n",
        "    print(\"f1-score\", f1_score(y_test, predict))\n",
        "    \n",
        "    # 틀린파일\n",
        "    wrongs = list(zip(X_test[y_test != predict], y_test[y_test != predict]))\n",
        "    return wrongs\n",
        "\n",
        "\n",
        "clf = train(X_train, y_train, model=\"rf\")\n",
        "_ = evaluate(clf, X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pA7S3qrmFbWe"
      },
      "source": [
        "\n",
        "\n",
        "> #### Ember\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7s4sHtlFFdRJ"
      },
      "source": [
        "clf = load_model(model=\"lgb\", random_state=SEED)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "predict = clf.predict(X_test)\n",
        "\n",
        "print(\"accuracy\", clf.score(X_test, y_test))\n",
        "print(\"precision\", precision_score(y_test, predict))\n",
        "print(\"recall\", recall_score(y_test, predict))\n",
        "print(\"f1-score\", f1_score(y_test, predict))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kiGgOD1GGepm"
      },
      "source": [
        "### 판별 분기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ps0LaKpEGiQZ"
      },
      "source": [
        "from sklearn import tree\n",
        "\n",
        "for dtree in clf.estimators_[:1]:\n",
        "    tree.export_graphviz(dtree\n",
        "                            , max_depth=2\n",
        "                            , out_file='tree.dot'\n",
        "                            , feature_names=peminer_header\n",
        "                            , class_names=['benign', 'mal']\n",
        "                            , filled=True\n",
        "                            , rounded=True\n",
        "                            , special_characters=True)\n",
        "\n",
        "    # Convert to png using system command (requires Graphviz)\n",
        "    os.system('dot ' + '-Tpng ' + 'tree.dot ' + '-o ' + 'tree.png ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ey8RGy1kG7Td"
      },
      "source": [
        "### 특징 중요도 그래프"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvmyvUskG98W"
      },
      "source": [
        "> #### PE-Miner"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKpRMFFTHBxF"
      },
      "source": [
        "def draw_feature_importance_plot():\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    feat_importances = pd.Series(clf.feature_importances_, index=peminer_header)\n",
        "    feat_importances.nlargest(24).plot(kind='bar')\n",
        "    plt.ylabel(\"score\", fontsize=16)\n",
        "    plt.yticks(fontsize=16)\n",
        "    plt.xticks(fontsize=16)\n",
        "    plt.savefig(\"peminer importance\")\n",
        "\n",
        "draw_feature_importance_plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-p825LG6HDej"
      },
      "source": [
        "> #### Ember"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnXITqAaHIMK"
      },
      "source": [
        "section, dll, function, eat = 50, 256, 1024, 128    \n",
        "\n",
        "header = [f\"Byte Histogram {i}\" for i in range(256)] +\\\n",
        "[f\"Byte Entropy Histogram {i}\" for i in range(256)] +\\\n",
        "[f\"String Info {i}\" for i in range(104)]+\\\n",
        "[f\"General File Info {i}\" for i in range(10)]+\\\n",
        "[f\"Header Info {i}\" for i in range(62)]+\\\n",
        "[f\"Section(General) {i}\" for i in range(5)]+\\\n",
        "[f\"Section(Size) {i}\" for i in range(section)]+\\\n",
        "[f\"Section(Entropy) {i}\" for i in range(section)]+\\\n",
        "[f\"Section(Virtual Size) {i}\" for i in range(section)]+\\\n",
        "[f\"Section(Entry) {i}\" for i in range(section)]+\\\n",
        "[f\"Section(Characteristic) {i}\" for i in range(section)]+\\\n",
        "[f\"Imports(DLL) {i}\" for i in range(dll)]+\\\n",
        "[f\"Imports(Function) {i}\" for i in range(function)]+\\\n",
        "[f\"Exports(Function) {i}\" for i in range(eat)]+\\\n",
        "[f\"Data Directory {i}\" for i in range(30)]\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "feat_importances = pd.Series(clf.feature_importances_, index=header)\n",
        "feat_importances.nlargest(24).plot(kind='bar')\n",
        "plt.ylabel(\"score\", fontsize=16)\n",
        "plt.yticks(fontsize=16)\n",
        "plt.xticks(fontsize=16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4I_iZv3HNyD"
      },
      "source": [
        "### 혼동 행렬"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pztd4b0pHSwH"
      },
      "source": [
        "\n",
        "\n",
        "> #### PE-Miner\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PkhK3NBHVSn"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "\n",
        "disp = plot_confusion_matrix(clf, X_test, y_test, normalize=\"true\", cmap=plt.cm.Blues)\n",
        "disp.figure_.savefig(\"실험3 PEminer\") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbsoey_xHXyR"
      },
      "source": [
        "\n",
        "\n",
        "> #### Ember\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8wzwKFAHZ3M"
      },
      "source": [
        "disp = plot_confusion_matrix(clf, X_test, y_test, normalize=\"true\", cmap=plt.cm.Blues)\n",
        "disp.figure_.savefig(\"실험3 Ember\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_X1XwrrHjKp"
      },
      "source": [
        "### 최적 파라미터 탐색 (Grid Search)\n",
        "- 학습 전, 모델의 최적 파라미터를 찾아 학습하고 싶을 때 사용\n",
        "- 기본(default) 파라미터 결과와 비교 필수"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61kXq0nMHmXf"
      },
      "source": [
        "\n",
        "\n",
        "> #### PE-Miner\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJ5CIslyHqOH"
      },
      "source": [
        "피처 차원 줄이기(Feature Selection) : PE-Miner만 하는 과정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKSDbvkZHvwq"
      },
      "source": [
        "rfe = RFE(estimator=clf)\n",
        "rfe.fit(X_train, y_train)\n",
        "\n",
        "pipeline = Pipeline(steps=[(\"rfe\", rfe), (\"clf\", clf)])\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "pipeline.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kw7ksuo8Hxxp"
      },
      "source": [
        "print(\"현재 랜덤포레스트 파라미터\")\n",
        "pprint(clf.get_params())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VR-qUGI7Ii8l"
      },
      "source": [
        "param_grid = {\n",
        "    'bootstrap': [True],\n",
        "    'max_depth': [80, 90, 100, 110, None],\n",
        "    'max_features': [2, 3],\n",
        "    'min_samples_leaf': [3, 4, 5],\n",
        "    'min_samples_split': [8, 10, 12],\n",
        "    'n_estimators': [100, 128, 256, 1024]\n",
        "}\n",
        "grid_search = GridSearchCV(estimator=clf, param_grid=param_grid, \n",
        "                          cv=5, n_jobs=-1, verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfXa4ONnH7Md"
      },
      "source": [
        "\n",
        "\n",
        "> #### Ember\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njwUv62aH9XC"
      },
      "source": [
        "print(\"현재 랜덤포레스트 파라미터\")\n",
        "pprint(clf.get_params())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeuJY5_FIXil"
      },
      "source": [
        "param_grid = {\n",
        "    'bootstrap': [True],\n",
        "    'max_depth': [80, 90, 100, 110, None],\n",
        "    'max_features': [2, 3],\n",
        "    'min_samples_leaf': [3, 4, 5],\n",
        "    'min_samples_split': [8, 10, 12],\n",
        "    'n_estimators': [100, 128, 256, 1024]\n",
        "}\n",
        "grid_search = GridSearchCV(estimator=clf, param_grid=param_grid, \n",
        "                          cv=5, n_jobs=-1, verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vudpUU_SIYFx"
      },
      "source": [
        "grid_search.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSoLBRHwIbm9"
      },
      "source": [
        "pprint(grid_search.best_params_)\n",
        "\n",
        "best_grid = grid_search.best_estimator_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "an2ZZGFcIdVu"
      },
      "source": [
        "clf.set_params(**grid_search.best_params_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O07N1gCYIfCh"
      },
      "source": [
        "best_grid.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Py_x4etfLhWI"
      },
      "source": [
        "### 참고자료"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9DZlCoVLxL8"
      },
      "source": [
        "#### [PE-Miner]\n",
        "\n",
        "- #### 피처 추출 코드 : https://bit.ly/3amOhp2\n",
        "\n",
        "- #### 샘플 : https://bit.ly/31P7Z98\n",
        "\n",
        "- #### 학습 데이터 이름 : http://tiny.cc/9cdzsz\n",
        "\n",
        "- #### 학습 데이터 : http://tiny.cc/1cdzsz\n",
        "\n",
        "- #### 학습 라벨 : http://tiny.cc/gcdzsz\n",
        "\n",
        "- #### 검증 데이터 이름 : http://tiny.cc/2edzsz\n",
        "\n",
        "- #### 검증 데이터 : http://tiny.cc/zddzsz\n",
        "\n",
        "- #### 검증 라벨 : http://tiny.cc/4edzsz\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zw1J918RNwwR"
      },
      "source": [
        "#### [Ember]\n",
        "- #### 피처 추출 코드 : https://bit.ly/3gWqxuj\n",
        "\n",
        "- #### 학습 데이터 : https://bit.ly/2FkqtXn\n",
        "\n",
        "- #### 학습 라벨 : https://bit.ly/3amlIYV\n",
        "\n",
        "- #### 검증 데이터 : https://bit.ly/2PMXPQO\n",
        "\n",
        "- #### 검증 라벨 : https://bit.ly/2XYGbOe"
      ]
    }
  ]
}